{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cb91d6a3-fee8-49bc-a0a1-d6ff3103db80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer, BertConfig, BertForSequenceClassification, AutoTokenizer, AutoModelForMaskedLM, BartTokenizer, BartForConditionalGeneration, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "import textwrap\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
    "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f544ac6e-8abd-479f-a197-d61d3529a233",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('texts/FL_Brecko.txt', 'r') as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5fe257e5-1a6f-4b2d-a222-6e499acbe4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in input text: 37876\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize(text)\n",
    "num_tokens = len(tokens)\n",
    "\n",
    "print(f\"Number of tokens in input text: {num_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "aaf7295c-9cd3-4530-929c-62a915840793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2min 57s ± 191 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "def chunk_text(text, max_tokens):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "\n",
    "    for word in words:\n",
    "        trial_text = ' '.join(current_chunk + [word])\n",
    "        token_count = len(tokenizer.tokenize(trial_text))\n",
    "\n",
    "        if token_count > max_tokens:\n",
    "            chunks.append(' '.join(current_chunk))\n",
    "            current_chunk = [word]\n",
    "        else:\n",
    "            current_chunk.append(word)\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(' '.join(current_chunk))\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "\n",
    "chunks = chunk_text(text, max_tokens=1024)\n",
    "\n",
    "summaries = []\n",
    "for chunk in chunks:\n",
    "    inputs = tokenizer(chunk, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=1024)\n",
    "    summary_ids = model.generate(inputs['input_ids'], max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    summaries.append(summary)\n",
    "\n",
    "final_summary = ' '.join(summaries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0d342d0e-02a3-4149-bde0-2a36d3cd12a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary saved to CSV successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2786450/3200570203.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(new_data, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "csv_path = 'csv/SummaryText.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "new_data = pd.DataFrame({\n",
    "    'Name of Article': [\"SAMI2022\"],\n",
    "    'Summarized Text': [final_summary]\n",
    "})\n",
    "\n",
    "df = df.append(new_data, ignore_index=True)\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "\n",
    "print(\"Summary saved to CSV successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
